{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import h5py\n",
    "# Read the GRIB2 file\n",
    "\n",
    "\n",
    "ds = xr.open_dataset('PrecipRate_00.00/20221223/MRMS_PrecipRate_00.00_20221223-045000.grib2', engine='cfgrib')\n",
    "lats = ds.latitude.values\n",
    "lons = ds.longitude.values\n",
    "lons = np.where(lons > 180, lons - 360, lons)\n",
    "Lat_m, Lon_m = np.meshgrid(lats, lons, indexing='ij')\n",
    "GMIfiles = sorted(os.listdir('GMI'))\n",
    "dataset1 = h5py.File('GMI/'+GMIfiles[122])\n",
    "Lat_g = dataset1['/S2/Latitude'][:]\n",
    "Lon_g = dataset1['/S2/Longitude'][:]\n",
    "scantime1 = dataset1['/S2/ScanTime/SecondOfDay'][:]\n",
    "scantime2 = dataset1['/S2/ScanTime/DayOfYear'][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c66dd",
   "metadata": {},
   "source": [
    "**Finding GMI Orbits crossing CONUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712, 1875)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = h5py.File('GMI/'+GMIfiles[129])\n",
    "Lat_g = dataset1['/S2/Latitude'][:]\n",
    "Lon_g = dataset1['/S2/Longitude'][:]\n",
    "scantime1 = dataset1['/S2/ScanTime/SecondOfDay'][:]\n",
    "scantime2 = dataset1['/S2/ScanTime/DayOfYear'][:]\n",
    "\n",
    "def find_gmi_conus_indices(Lat_g, Lon_g, Lat_m, Lon_m):\n",
    "\n",
    "    # Find MRMS coverage boundaries\n",
    "    mrms_lat_min = np.min(Lat_m)\n",
    "    mrms_lat_max = np.max(Lat_m)\n",
    "    mrms_lon_min = np.min(Lon_m)\n",
    "    mrms_lon_max = np.max(Lon_m)\n",
    "    \n",
    "    # Initialize arrays to track which rows are fully within MRMS coverage\n",
    "    rows_in_conus = []\n",
    "    \n",
    "    # Check each row of GMI data\n",
    "    for i in range(Lat_g.shape[0]):\n",
    "        # Check if all points in this row are within MRMS boundaries\n",
    "        lat_row = Lat_g[i, :]\n",
    "        lon_row = Lon_g[i, :]\n",
    "        \n",
    "        # Check if all points in this row are within MRMS boundaries\n",
    "        lat_in_bounds = np.all((lat_row >= mrms_lat_min) & (lat_row <= mrms_lat_max))\n",
    "        lon_in_bounds = np.all((lon_row >= mrms_lon_min) & (lon_row <= mrms_lon_max))\n",
    "        \n",
    "        if lat_in_bounds and lon_in_bounds:\n",
    "            rows_in_conus.append(i)\n",
    "    \n",
    "    # Find continuous sequence of rows\n",
    "    if len(rows_in_conus) > 0:\n",
    "        start_index = rows_in_conus[0]\n",
    "        end_index = rows_in_conus[-1]\n",
    "        \n",
    "        # Verify continuity\n",
    "        if not all(rows_in_conus[i+1] - rows_in_conus[i] == 1 \n",
    "                  for i in range(len(rows_in_conus)-1)):\n",
    "            print(\"Warning: Found gaps in CONUS coverage\")\n",
    "            \n",
    "        return start_index, end_index\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Usage example:\n",
    "start_idx, end_idx = find_gmi_conus_indices(Lat_g, Lon_g, Lat_m, Lon_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1981ea5",
   "metadata": {},
   "source": [
    "**Creating Spatial-temporal matched filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyList = []\n",
    "\n",
    "for i in range(len(GMIfiles)):\n",
    "    dataset1 = h5py.File('GMI/'+GMIfiles[i])\n",
    "    Lat_g = dataset1['/S2/Latitude'][:]\n",
    "    Lon_g = dataset1['/S2/Longitude'][:]\n",
    "    \n",
    "    start_idx, end_idx = find_gmi_conus_indices(Lat_g, Lon_g, Lat_m, Lon_m)\n",
    "    \n",
    "    if (start_idx is not None):\n",
    "        bb = end_idx-start_idx\n",
    "        if bb>289:\n",
    "            MyList.append([GMIfiles[i],start_idx,end_idx])\n",
    "            bb = end_idx-start_idx\n",
    "            \n",
    "            print(bb)\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "def generate_unique_mrms_filenames(scantime_SecondOfDay, scantime_DayOfYear):\n",
    "   rate_filenames = set()\n",
    "   flag_filenames = set()\n",
    "   base_date = datetime.datetime(2022, 1, 1)\n",
    "   \n",
    "   for day, sec in zip(scantime_DayOfYear, scantime_SecondOfDay):\n",
    "       curr_date = base_date + datetime.timedelta(days=int(day-1), seconds=int(sec))\n",
    "       minutes = curr_date.minute + curr_date.second/60\n",
    "       rounded_minutes = round(minutes/2) * 2\n",
    "       rounded_date = curr_date.replace(minute=0, second=0) + datetime.timedelta(minutes=rounded_minutes)\n",
    "       \n",
    "       folder = rounded_date.strftime(\"%Y%m%d\")\n",
    "       timestamp = rounded_date.strftime(\"%Y%m%d-%H%M%S\")\n",
    "       \n",
    "       rate_path = f'PrecipRate_00.00/{folder}/MRMS_PrecipRate_00.00_{timestamp}.grib2'\n",
    "       flag_path = f'PrecipFlag_00.00/{folder}/MRMS_PrecipFlag_00.00_{timestamp}.grib2'\n",
    "       \n",
    "       rate_filenames.add(rate_path)\n",
    "       flag_filenames.add(flag_path)\n",
    "\n",
    "       Final_list = [sorted(list(rate_filenames)),sorted(list(flag_filenames))]\n",
    "   \n",
    "   return Final_list\n",
    "\n",
    "\n",
    "def get_mapping_indices(scantime_SecondOfDay, scantime_DayOfYear, filenames):\n",
    "   \n",
    "   \n",
    "   base_date = datetime.datetime(2022, 1, 1)\n",
    "   scan_times = [base_date + datetime.timedelta(days=int(day-1), seconds=int(sec)) \n",
    "                for day, sec in zip(scantime_DayOfYear, scantime_SecondOfDay)]\n",
    "   \n",
    "   file_times = []\n",
    "   for filename in filenames:\n",
    "       timestamp = filename.split('_')[-1].replace('.grib2', '')\n",
    "       file_time = datetime.datetime.strptime(timestamp, '%Y%m%d-%H%M%S')\n",
    "       file_times.append(file_time)\n",
    "   \n",
    "   mapping_indices = []\n",
    "   for scan_time in scan_times:\n",
    "       time_diffs = [abs((file_time - scan_time).total_seconds()) for file_time in file_times]\n",
    "       closest_idx = time_diffs.index(min(time_diffs))\n",
    "       mapping_indices.append(closest_idx)\n",
    "   \n",
    "   return mapping_indices\n",
    "\n",
    "\n",
    "Final_List = []\n",
    "for i in range(len(MyList)): \n",
    "    dataset1 = h5py.File('GMI/'+ MyList[i][0])\n",
    "    scantime1 = dataset1['/S2/ScanTime/SecondOfDay'][:]\n",
    "    scantime2 = dataset1['/S2/ScanTime/DayOfYear'][:]\n",
    "    start_f = MyList[i][1]+2\n",
    "    end_f = MyList[i][2]-2\n",
    "    scantime_SecondOfDay = scantime1[start_f:end_f+1]\n",
    "    scantime_DayOfYear = scantime2[start_f:end_f+1]\n",
    "    List = generate_unique_mrms_filenames(scantime_SecondOfDay, scantime_DayOfYear)\n",
    "    indices = get_mapping_indices(scantime_SecondOfDay, scantime_DayOfYear, List[0])\n",
    "    \n",
    "    missing_files = [file for file in List[0]+List[1] if not os.path.exists(file)]\n",
    "\n",
    "    if missing_files:\n",
    "        print(\" files don't exist.\")\n",
    "    else:\n",
    "        Final_List.append(MyList[i] + [indices] + List)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "f = open(\"Final_list.pkl\", \"rb\") \n",
    "mylist = pickle.load(f)\n",
    "\n",
    "ds = xr.open_dataset('PrecipRate_00.00/20221223/MRMS_PrecipRate_00.00_20221223-045000.grib2', engine='cfgrib')\n",
    "lats = ds.latitude.values\n",
    "lons = ds.longitude.values\n",
    "lons = np.where(lons > 180, lons - 360, lons)\n",
    "Lat_m, Lon_m = np.meshgrid(lats, lons, indexing='ij')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59b4d1",
   "metadata": {},
   "source": [
    "**Creating Fake Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_padding_to_gmi(lat_conus, lon_conus, n_pads=2):\n",
    "    rows, cols = lat_conus.shape\n",
    "    new_cols = cols + 2 * n_pads\n",
    "    \n",
    "    # Initialize padded arrays\n",
    "    lat_padded = np.zeros((rows, new_cols))\n",
    "    lon_padded = np.zeros((rows, new_cols))\n",
    "    \n",
    "    # Copy original data to middle\n",
    "    lat_padded[:, n_pads:-n_pads] = lat_conus\n",
    "    lon_padded[:, n_pads:-n_pads] = lon_conus\n",
    "    \n",
    "    # Calculate differences at left edge\n",
    "    lat_diff_left = lat_conus[:, 1] - lat_conus[:, 0]\n",
    "    lon_diff_left = lon_conus[:, 1] - lon_conus[:, 0]\n",
    "    \n",
    "    # Calculate differences at right edge\n",
    "    lat_diff_right = lat_conus[:, -1] - lat_conus[:, -2]\n",
    "    lon_diff_right = lon_conus[:, -1] - lon_conus[:, -2]\n",
    "    \n",
    "    # Add left padding grids\n",
    "    for i in range(n_pads):\n",
    "        lat_padded[:, n_pads-1-i] = lat_padded[:, n_pads-i] - lat_diff_left\n",
    "        lon_padded[:, n_pads-1-i] = lon_padded[:, n_pads-i] - lon_diff_left\n",
    "    \n",
    "    # Add right padding grids\n",
    "    for i in range(n_pads):\n",
    "        lat_padded[:, -n_pads+i] = lat_padded[:, -n_pads-1+i] + lat_diff_right\n",
    "        lon_padded[:, -n_pads+i] = lon_padded[:, -n_pads-1+i] + lon_diff_right\n",
    "    \n",
    "    return lat_padded, lon_padded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a06fe5",
   "metadata": {},
   "source": [
    "**Gathering MRMS points falling inside of GMI grids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_reverse_nearest_neighbors(Lat_m, Lon_m, Lat_conus, Lon_conus):\n",
    "\n",
    "    lat_padded, lon_padded = add_padding_to_gmi(Lat_conus, Lon_conus, n_pads=2)\n",
    "\n",
    "\n",
    "\n",
    "    # Stack coordinates more efficiently\n",
    "    mrms_points = np.stack((Lat_m.ravel(), Lon_m.ravel()), axis=1)\n",
    "    gmi_points = np.stack((lat_padded.ravel(), lon_padded.ravel()), axis=1)\n",
    "    \n",
    "    # Build KD-tree with optimized leaf size\n",
    "    tree = cKDTree(gmi_points)\n",
    "    \n",
    "    # Find nearest GMI point for each MRMS point using all available cores\n",
    "    _, indices = tree.query(mrms_points, workers=-1, distance_upper_bound=np.inf)\n",
    "    \n",
    "    # Use defaultdict for faster accumulation\n",
    "    temp_dict = defaultdict(list)\n",
    "    \n",
    "    # Pre-calculate indices for better performance\n",
    "    flat_mrms_indices = np.arange(len(mrms_points))\n",
    "    mrms_i = flat_mrms_indices // Lat_m.shape[1]\n",
    "    mrms_j = flat_mrms_indices % Lat_m.shape[1]\n",
    "    \n",
    "    gmi_i = indices // lat_padded.shape[1]\n",
    "    gmi_j = indices % lat_padded.shape[1]\n",
    "    \n",
    "    # Fast population of the dictionary\n",
    "    for idx in range(len(indices)):\n",
    "        temp_dict[(gmi_i[idx], gmi_j[idx])].append((mrms_i[idx], mrms_j[idx]))\n",
    "    \n",
    "    # Create output array\n",
    "    reverse_neighbors = np.empty(lat_padded.shape, dtype=object)\n",
    "    \n",
    "    # Convert dictionary to array efficiently\n",
    "    for i in range(lat_padded.shape[0]):\n",
    "        for j in range(lat_padded.shape[1]):\n",
    "            reverse_neighbors[i, j] = temp_dict.get((i, j), [])\n",
    "\n",
    "            final = reverse_neighbors[2:-2,2:-2]\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlagRate(finall, P_rate, P_flag): \n",
    "\n",
    "    Rate = np.zeros(finall.shape, dtype=object)\n",
    "    Flag = np.zeros(finall.shape, dtype=object)\n",
    "\n",
    "    for i in range(finall.shape[0]):\n",
    "        for j in range(finall.shape[1]):\n",
    "            Rate[i,j] = np.array([P_rate[finall[i,j][k]] for k in range(len(finall[i,j]))])\n",
    "            Flag[i,j] = np.array([P_flag[finall[i,j][k]] for k in range(len(finall[i,j]))])\n",
    "\n",
    "    return Rate, Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41286ac1",
   "metadata": {},
   "source": [
    "**Deciding on flag & rate of GMI grids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42285ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_mrms_vector(flag_vector, rate_vector):\n",
    "\n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    flag_vector = np.array(flag_vector)\n",
    "    rate_vector = np.array(rate_vector)\n",
    "    \n",
    "    # Count occurrences of each type\n",
    "    rain_flags = [1, 6, 7, 10, 91, 96]  # All rain-type flags\n",
    "    snow_flags = [3]  # Snow flag\n",
    "    no_precip_flags = [0]  # No precipitation\n",
    "    no_coverage_flags = [-3]  # No coverage\n",
    "    \n",
    "    rain_count = np.sum(np.isin(flag_vector, rain_flags))\n",
    "    snow_count = np.sum(np.isin(flag_vector, snow_flags))\n",
    "    no_precip_count = np.sum(np.isin(flag_vector, no_precip_flags))\n",
    "    no_coverage_count = np.sum(np.isin(flag_vector, no_coverage_flags))\n",
    "    \n",
    "    vector_length = len(flag_vector)\n",
    "    \n",
    "    # First check if we only have no_coverage and no_precip\n",
    "    if rain_count == 0 and snow_count == 0:\n",
    "        if no_coverage_count > no_precip_count:\n",
    "            return -3, -3\n",
    "        else:\n",
    "            return 0, 0\n",
    "    \n",
    "    # Compare rain and snow counts\n",
    "    if snow_count > rain_count:\n",
    "        # Snow is majority\n",
    "        # Calculate rate: sum of snow rates divided by vector length\n",
    "        snow_mask = np.isin(flag_vector, snow_flags)\n",
    "        total_snow_rate = np.sum(rate_vector[snow_mask])\n",
    "        final_rate = total_snow_rate / vector_length\n",
    "        return 2, final_rate\n",
    "    else:\n",
    "        # Rain is majority (or equal)\n",
    "        # Calculate rate: sum of rain rates divided by vector length\n",
    "        rain_mask = np.isin(flag_vector, rain_flags)\n",
    "        total_rain_rate = np.sum(rate_vector[rain_mask])\n",
    "        final_rate = total_rain_rate / vector_length\n",
    "        return 1, final_rate\n",
    "\n",
    "def process_mrms_grid(mapped_flag, mapped_rate):\n",
    "\n",
    "    a = mapped_flag.shape[0]\n",
    "    b = mapped_flag.shape[1]\n",
    "    processed_flags = np.empty((a, b), dtype=int)  # Integer type for flags\n",
    "    processed_rates = np.empty((a, b), dtype=float)\n",
    "    \n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            # Extract the vectors at this position\n",
    "            flag_vector = mapped_flag[i,j]\n",
    "            rate_vector = mapped_rate[i,j]\n",
    "            \n",
    "            # Process only if we have valid vectors\n",
    "            if len(flag_vector) > 0:\n",
    "                flag, rate = process_mrms_vector(flag_vector, rate_vector)\n",
    "            else:\n",
    "                flag, rate = -3, -3\n",
    "                \n",
    "            processed_flags[i,j] = flag\n",
    "            processed_rates[i,j] = rate\n",
    "            \n",
    "    return processed_flags, processed_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926de7f1",
   "metadata": {},
   "source": [
    "**Excecuting functions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4900f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "Chunk_index = [200,500]\n",
    "\n",
    "\n",
    "for i in range(Chunk_index[0],Chunk_index[-1]):\n",
    "    \n",
    "    dataset1 = h5py.File('GMI/'+mylist[i][0])\n",
    "    Lat_g = dataset1['/S2/Latitude'][:]\n",
    "    Lon_g = dataset1['/S2/Longitude'][:]\n",
    "    \n",
    "    \n",
    "    Lat_conus = Lat_g[mylist[i][1]:mylist[i][2]+1, :]\n",
    "    Lon_conus = Lon_g[mylist[i][1]:mylist[i][2]+1, :]\n",
    "\n",
    "\n",
    "    Preflag = [0 for e in range(len(mylist[i][-1]))]\n",
    "    PreRate = [0 for e in range(len(mylist[i][-2]))]\n",
    "\n",
    "    Preflag_O = [0 for e in range(len(mylist[i][-1]))]\n",
    "    PreRate_O = [0 for e in range(len(mylist[i][-2]))]\n",
    "\n",
    "\n",
    "    for k in range(len(Preflag_O)): \n",
    "        ds1 = xr.open_dataset(mylist[i][-2][k], engine='cfgrib')\n",
    "        PreRate_O[k] = ds1.unknown.values\n",
    "        ds2 = xr.open_dataset(mylist[i][-1][k], engine='cfgrib')\n",
    "        Preflag_O[k] = ds2.unknown.values\n",
    "        \n",
    "    finall = find_reverse_nearest_neighbors(Lat_m, Lon_m, Lat_conus, Lon_conus)     \n",
    "\n",
    "\n",
    "    for p in range(len(Preflag)): \n",
    "\n",
    "        PreRate[p], Preflag[p] = FlagRate(finall, PreRate_O[p], Preflag_O[p])\n",
    "\n",
    "    indices = mylist[i][3]\n",
    "    Final_Rate = np.zeros(finall.shape, dtype=object)\n",
    "    Final_Flag = np.zeros(finall.shape, dtype=object)\n",
    "\n",
    "    for r in range(finall.shape[0]):\n",
    "        Final_Rate[r,:] = PreRate[indices[r]][r,:]\n",
    "        Final_Flag[r,:] = Preflag[indices[r]][r,:]\n",
    "        \n",
    "    processed_flags, processed_rates = process_mrms_grid(Final_Flag, Final_Rate)\n",
    "    \n",
    "    start_f = mylist[i][1]+2\n",
    "    end_f = mylist[i][2]-2\n",
    "    \n",
    "\n",
    "    \n",
    "    GMI_FLAG = np.full(Lon_g.shape, np.nan)\n",
    "    GMI_RATE = np.full(Lon_g.shape, np.nan)\n",
    "    \n",
    "    GMI_FLAG[start_f:end_f+1:] = processed_flags\n",
    "    GMI_RATE[start_f:end_f+1:] = processed_rates\n",
    "    \n",
    "    GMI_FLAG_RAW = np.full(Lon_g.shape, np.nan, dtype=object)\n",
    "    GMI_RATE_RAW = np.full(Lon_g.shape, np.nan, dtype=object)\n",
    "    \n",
    "    GMI_FLAG_RAW[start_f:end_f+1:] = Final_Flag\n",
    "    GMI_RATE_RAW[start_f:end_f+1:] = Final_Rate\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    np.save('RAW/'+'RFlag'+'.' +mylist[i][0].split('.')[5], GMI_FLAG_RAW)\n",
    "    np.save('RAW/'+'RRate'+'.' +mylist[i][0].split('.')[5], GMI_RATE_RAW)\n",
    "    np.save('FILE/'+'Flag'+'.' +mylist[i][0].split('.')[5], GMI_FLAG)\n",
    "    np.save('FILE/'+'Rate'+'.' +mylist[i][0].split('.')[5], GMI_RATE)\n",
    "    \n",
    "    del GMI_FLAG, GMI_RATE, GMI_FLAG_RAW, GMI_RATE_RAW, Preflag_O, PreRate_O, Preflag, PreRate\n",
    "    \n",
    "    print(f'#{i} has been done')\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d9bc1",
   "metadata": {},
   "source": [
    "**Visualization of an example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8206fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import h5py\n",
    "Flag_file = xr.open_dataset('MRMS_PrecipFlag_00.00_20221223-040400.grib2', engine='cfgrib')\n",
    "Rate_file = xr.open_dataset('MRMS_PrecipRate_00.00_20221223-040400.grib2', engine='cfgrib')\n",
    "\n",
    "lats  = Rate_file.latitude.values\n",
    "lons  = Rate_file.longitude.values\n",
    "lons = np.where(lons > 180, lons - 360, lons)\n",
    "\n",
    "Flag_mapped = np.load(\"Flag.050100.npy\")\n",
    "Rate_mapped = np.load(\"Rate.050100.npy\")\n",
    "\n",
    "Lat_m, Lon_m = np.meshgrid(lats, lons, indexing='ij')\n",
    "\n",
    "Flag_MRMS = Flag_file.unknown.values\n",
    "Rate_MRMS = Rate_file.unknown.values\n",
    "\n",
    "\n",
    "GMI_dateset = h5py.File('1B.GPM.GMI.TB2021.20221223-S030751-E044025.050100.V07A.HDF5')\n",
    "Lat_g = GMI_dateset['/S2/Latitude'][:]\n",
    "Lon_g = GMI_dateset['/S2/Longitude'][:]\n",
    "\n",
    "del lats, lons, Flag_file, Rate_file, GMI_dateset\n",
    "\n",
    "\n",
    "Rain_MRMS = Rate_MRMS.copy()\n",
    "Rain_MRMS[np.where( (Flag_MRMS != 1) &(Flag_MRMS != 6) & (Flag_MRMS != 7) & (Flag_MRMS != 10) & (Flag_MRMS != 91)& (Flag_MRMS != 96) )] = 0\n",
    "Rain_MRMS[np.where( (Flag_MRMS == 3))] = np.nan\n",
    "\n",
    "Snow_MRMS = Rate_MRMS.copy()\n",
    "Snow_MRMS[np.where( (Flag_MRMS != 3))] = 0\n",
    "Snow_MRMS[np.where( (Flag_MRMS == 1) |(Flag_MRMS == 6) | (Flag_MRMS == 7) | (Flag_MRMS == 10) | (Flag_MRMS == 91)| (Flag_MRMS == 96) )] = np.nan\n",
    "Snow_MRMS.max()\n",
    "\n",
    "Rain_Mapped = Rate_mapped.copy()\n",
    "\n",
    "Rain_Mapped[np.where( (Flag_mapped != 1))] = 0\n",
    "Rain_Mapped[np.where( (Flag_mapped == 2))] = np.nan\n",
    "\n",
    "Snow_Mapped = Rate_mapped.copy()\n",
    "\n",
    "Snow_Mapped[np.where( (Flag_mapped != 2))] = 0\n",
    "Snow_Mapped[np.where( (Flag_mapped == 1))] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Define custom colormap\n",
    "colors = [\"#A9A9A9\", \"#FFA500\", \"#ADD8E6\", \"#FFC0CB\"]  # Gray, Orange, Pale Blue, Pink\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3, 4]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "#ax.set_extent([Lon_ATMS.min(), Lon_ATMS.max(), Lat_ATMS.min(), Lat_ATMS.max()], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5, linestyle=':')\n",
    "    \n",
    "g1 = ax.gridlines(draw_labels=True)\n",
    "g1.right_labels = False\n",
    "g1.bottom_labels = False\n",
    "g1.xlabel_style = {'size':10, 'weight':'bold'}\n",
    "g1.ylabel_style = {'size':10, 'weight':'bold'}\n",
    "\n",
    "# Plot precipitation flags\n",
    "colors = ['lightgray', 'green', 'orange', 'pink']\n",
    "\n",
    "custom_cmap_ATMS = plt.cm.colors.LinearSegmentedColormap.from_list('custom', colors)\n",
    "import numpy.ma as ma\n",
    "mask_lon = (Lon_g > 179.5) | (Lon_g < -179.5)\n",
    "mask_lat = (Lat_g > 89.5) | (Lat_g < -89.5)\n",
    "mask = mask_lon | mask_lat\n",
    "PrF_plot_masked1 = np.ma.masked_where(mask, Rain_Mapped)\n",
    "mesh1 = ax.pcolormesh(Lon_g, Lat_g, PrF_plot_masked1,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        cmap = custom_cmap_ATMS,\n",
    "                        vmin =0, \n",
    "                        vmax =5)\n",
    "\n",
    "\n",
    "\n",
    "# Plot precipitation flags\n",
    "colors2 = [\n",
    "    \"#E0E0E0\",  # Very Light Gray (Little to no snowfall)\n",
    "    \"#A9EAFE\",  # Light Cyan (Light snowfall)\n",
    "    \"#00BFFF\",  # Deep Sky Blue (Moderate snowfall)\n",
    "    \"#0000FF\",  # Blue (Heavy snowfall)\n",
    "    \"#9400D3\"   # Dark Violet (Extreme snowfall, brighter purple)\n",
    "]\n",
    "\n",
    "\n",
    "custom_cmap_ATMS = plt.cm.colors.LinearSegmentedColormap.from_list('custom', colors2)\n",
    "import numpy.ma as ma\n",
    "mask_lon = (Lon_g > 179.5) | (Lon_g < -179.5)\n",
    "mask_lat = (Lat_g > 89.5) | (Lat_g < -89.5)\n",
    "mask = mask_lon | mask_lat\n",
    "PrF_plot_masked2 = np.ma.masked_where(mask, Snow_Mapped)\n",
    "\n",
    "mesh2 = ax.pcolormesh(Lon_g, Lat_g, PrF_plot_masked2,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        cmap = custom_cmap_ATMS,\n",
    "                        vmin =0, \n",
    "                        vmax =2)\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "\n",
    "cbar1_ax = fig.add_axes([0.906, 0.54, 0.01, 0.33])  # Top colorbar\n",
    "cbar2_ax = fig.add_axes([0.906, 0.12, 0.01, 0.33])  # Bottom colorbar\n",
    "\n",
    "# Add colorbars\n",
    "cbar1 = fig.colorbar(mesh1, cax=cbar1_ax)\n",
    "cbar1.set_label('Rain Rate (mm/h)', weight='bold')\n",
    "cbar1.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "cbar2 = fig.colorbar(mesh2, cax=cbar2_ax)\n",
    "cbar2.set_label('Snow Rate (mm/h)', weight='bold')\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"Mapped MRMS on GMI Orbit #50100\", fontsize = 16, fontweight='bold')\n",
    "\n",
    "ax.set_extent([-125, -66.5, 24, 49])\n",
    "\n",
    "plt.savefig('Mapped', dpi = 500)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "# Define custom colormap\n",
    "colors = [\"#A9A9A9\", \"#FFA500\", \"#ADD8E6\", \"#FFC0CB\"]  # Gray, Orange, Pale Blue, Pink\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3, 4]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "#ax.set_extent([Lon_ATMS.min(), Lon_ATMS.max(), Lat_ATMS.min(), Lat_ATMS.max()], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5, linestyle=':')\n",
    "    \n",
    "g1 = ax.gridlines(draw_labels=True)\n",
    "g1.right_labels = False\n",
    "g1.bottom_labels = False\n",
    "g1.xlabel_style = {'size':10, 'weight':'bold'}\n",
    "g1.ylabel_style = {'size':10, 'weight':'bold'}\n",
    "\n",
    "# Plot precipitation flags\n",
    "colors = ['lightgray', 'green', 'orange', 'pink']\n",
    "\n",
    "custom_cmap_ATMS = plt.cm.colors.LinearSegmentedColormap.from_list('custom', colors)\n",
    "import numpy.ma as ma\n",
    "mask_lon = (Lon_g > 179.5) | (Lon_g < -179.5)\n",
    "mask_lat = (Lat_g > 89.5) | (Lat_g < -89.5)\n",
    "mask = mask_lon | mask_lat\n",
    "#PrF_plot_masked1 = np.ma.masked_where(mask, Rain_Mapped)\n",
    "mesh1 = ax.pcolormesh(Lon_m, Lat_m, Rain_MRMS,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        cmap = custom_cmap_ATMS,\n",
    "                        vmin =0, \n",
    "                        vmax =5)\n",
    "\n",
    "\n",
    "\n",
    "# Plot precipitation flags\n",
    "colors2 = [\n",
    "    \"#E0E0E0\",  # Very Light Gray (Little to no snowfall)\n",
    "    \"#A9EAFE\",  # Light Cyan (Light snowfall)\n",
    "    \"#00BFFF\",  # Deep Sky Blue (Moderate snowfall)\n",
    "    \"#0000FF\",  # Blue (Heavy snowfall)\n",
    "    \"#9400D3\"   # Dark Violet (Extreme snowfall, brighter purple)\n",
    "]\n",
    "\n",
    "\n",
    "custom_cmap_ATMS = plt.cm.colors.LinearSegmentedColormap.from_list('custom', colors2)\n",
    "import numpy.ma as ma\n",
    "mask_lon = (Lon_g > 179.5) | (Lon_g < -179.5)\n",
    "mask_lat = (Lat_g > 89.5) | (Lat_g < -89.5)\n",
    "mask = mask_lon | mask_lat\n",
    "#PrF_plot_masked2 = np.ma.masked_where(mask, Snow_Mapped)\n",
    "\n",
    "mesh2 = ax.pcolormesh(Lon_m, Lat_m, Snow_MRMS,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        cmap = custom_cmap_ATMS,\n",
    "                        vmin =0, \n",
    "                        vmax =2)\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "\n",
    "cbar1_ax = fig.add_axes([0.906, 0.54, 0.01, 0.33])  # Top colorbar\n",
    "cbar2_ax = fig.add_axes([0.906, 0.12, 0.01, 0.33])  # Bottom colorbar\n",
    "\n",
    "# Add colorbars\n",
    "cbar1 = fig.colorbar(mesh1, cax=cbar1_ax)\n",
    "cbar1.set_label('Rain Rate (mm/h)', weight='bold')\n",
    "cbar1.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "cbar2 = fig.colorbar(mesh2, cax=cbar2_ax)\n",
    "cbar2.set_label('Snow Rate (mm/h)', weight='bold')\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"MRMS Precipitation\", fontsize = 16, fontweight='bold')\n",
    "\n",
    "ax.set_extent([-125, -66.5, 24, 49])\n",
    "\n",
    "plt.savefig('MRMS', dpi = 500)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
